{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "CapsNet Scikeras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f4c4917-22fb-4b10-879e-51c600e6c3af",
        "_uuid": "9b086e5ec535ad75eada3ca72bf5e6534251074f",
        "id": "SOu16YJjqsli"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The new model CapsuleNet proposed by Sara Sabour (and Geoffry Hinton) claims to deliver state of the art results on [MNIST](https://arxiv.org/abs/1710.09829). The kernel aims to create and train the model using the Kaggle Dataset and then make a submission to see where it actually ends up. Given the constraint of using a Kaggle Kernel means it can't be trained as long as we would like or with GPU's but IMHO if a model can't be reasonably well trained in an hour on a 28x28 dataset, that model probably won't be too useful in the immediate future.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "* Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
        "* Code adapted from https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py, and modified by K Scott Mander: https://www.kaggle.com/kmader/capsulenet-on-mnist\n",
        "*  Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "*     The code has been completely ported to TF2\n",
        "*     The entire CapsNet model is wrapped as a Scikit learn model, and hyperparameter tuning has been demonstrated using GridSearchCV. \n",
        "*     This also enables the model to be used in sklearn pipelines and other workflows.\n",
        "\n",
        "Result:\n",
        "    Validation accuracy > 99.5% after 20 epochs. Still under-fitting.\n",
        "    About 110 seconds per epoch on a single GTX1070 GPU card\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH91jxoiuLUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1016778-a7c5-470b-cc09-21012d4e4e1f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKLT5sH5B6-7",
        "outputId": "feb1b15f-0373-43df-db8c-b248bf986c3b"
      },
      "source": [
        "# !python -m pip install tensorflow==2.1.0\r\n",
        "# !python -m pip install keras==2.3.1\r\n",
        "!python -m pip install scikeras\r\n",
        "\r\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\r\n",
        "\r\n",
        "disable_eager_execution()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikeras\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/bb/f423fcc01cc51c6bc071175aadfae4bde246d33482375fe00fb0fc6e5caf/scikeras-0.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from scikeras) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from scikeras) (2.4.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (0.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (2.4.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.32.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras) (0.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (51.1.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->scikeras) (0.4.8)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e30e2e10-a909-485d-be9d-dc6f592911a7",
        "_uuid": "c7e569699c6d067cd9fdf9c77299775e399b2ef3",
        "trusted": true,
        "id": "3Cror1Nrqslk"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, initializers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import callbacks\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import plot_model as model_plotter\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor, BaseWrapper\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iVHKu6KHqslp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fda3542-d956-40d4-e26a-c9c62e6aad38"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xK2VFuV9qslu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26ecab3-6694-4b54-a2b1-6624156d857c"
      },
      "source": [
        "tf.keras.layers.Input"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.keras.engine.input_layer.Input>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9776fd57-44e0-4211-a7a5-c7e647a10704",
        "_uuid": "f4b5499a472b312d5c5f0274ad429567aced6841",
        "id": "FYq28ZX6qsly"
      },
      "source": [
        "# Capsule Layers \n",
        "Here is the implementation of the necessary layers for the CapsuleNet. These are not optimized yet and can be made significantly more performant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Opv555lfqsly"
      },
      "source": [
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "38e_A7-_qsl2"
      },
      "source": [
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_PUW7APUqsl6"
      },
      "source": [
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "167d39ca-ee32-4eec-a83b-86194252b14f",
        "_uuid": "90c180a9a8c20e3fb8a93c3eb42588927cfcd6b6",
        "trusted": true,
        "id": "Mi7c6pncqsl9"
      },
      "source": [
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        # Regard the first two dimensions as `batch` dimension, then\n",
        "        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=[inputs.shape[0], self.num_capsule, 1, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "\n",
        "            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n",
        "            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension, then\n",
        "                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return tf.squeeze(outputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(CapsuleLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "K7ovT5RAqsmB"
      },
      "source": [
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Jd14VkSIqsmF"
      },
      "source": [
        "from keras.backend import *\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "def own_batch_dot(x, y, axes=None):\n",
        "  \"\"\"Batchwise dot product.\n",
        "  `batch_dot` is used to compute dot product of `x` and `y` when\n",
        "  `x` and `y` are data in batch, i.e. in a shape of\n",
        "  `(batch_size, :)`.\n",
        "  `batch_dot` results in a tensor or variable with less dimensions\n",
        "  than the input. If the number of dimensions is reduced to 1,\n",
        "  we use `expand_dims` to make sure that ndim is at least 2.\n",
        "  Arguments:\n",
        "      x: Keras tensor or variable with `ndim >= 2`.\n",
        "      y: Keras tensor or variable with `ndim >= 2`.\n",
        "      axes: list of (or single) int with target dimensions.\n",
        "          The lengths of `axes[0]` and `axes[1]` should be the same.\n",
        "  Returns:\n",
        "      A tensor with shape equal to the concatenation of `x`'s shape\n",
        "      (less the dimension that was summed over) and `y`'s shape\n",
        "      (less the batch dimension and the dimension that was summed over).\n",
        "      If the final rank is 1, we reshape it to `(batch_size, 1)`.\n",
        "  Examples:\n",
        "      Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n",
        "      `batch_dot(x, y, axes=1) = [[17, 53]]` which is the main diagonal\n",
        "      of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n",
        "      elements.\n",
        "      Shape inference:\n",
        "      Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n",
        "      If `axes` is (1, 2), to find the output shape of resultant tensor,\n",
        "          loop through each dimension in `x`'s shape and `y`'s shape:\n",
        "      * `x.shape[0]` : 100 : append to output shape\n",
        "      * `x.shape[1]` : 20 : do not append to output shape,\n",
        "          dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n",
        "      * `y.shape[0]` : 100 : do not append to output shape,\n",
        "          always ignore first dimension of `y`\n",
        "      * `y.shape[1]` : 30 : append to output shape\n",
        "      * `y.shape[2]` : 20 : do not append to output shape,\n",
        "          dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n",
        "      `output_shape` = `(100, 30)`\n",
        "  ```python\n",
        "      >>> x_batch = K.ones(shape=(32, 20, 1))\n",
        "      >>> y_batch = K.ones(shape=(32, 30, 20))\n",
        "      >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n",
        "      >>> K.int_shape(xy_batch_dot)\n",
        "      (32, 1, 30)\n",
        "  ```\n",
        "  \"\"\"\n",
        "  if isinstance(axes, int):\n",
        "    axes = (axes, axes)\n",
        "  x_ndim = ndim(x)\n",
        "  y_ndim = ndim(y)\n",
        "  if axes is None:\n",
        "    # behaves like tf.batch_matmul as default\n",
        "    axes = [x_ndim - 1, y_ndim - 2]\n",
        "  if x_ndim > y_ndim:\n",
        "    diff = x_ndim - y_ndim\n",
        "    y = array_ops.reshape(y,\n",
        "                          array_ops.concat(\n",
        "                              [array_ops.shape(y), [1] * (diff)], axis=0))\n",
        "  elif y_ndim > x_ndim:\n",
        "    diff = y_ndim - x_ndim\n",
        "    x = array_ops.reshape(x,\n",
        "                          array_ops.concat(\n",
        "                              [array_ops.shape(x), [1] * (diff)], axis=0))\n",
        "  else:\n",
        "    diff = 0\n",
        "  if ndim(x) == 2 and ndim(y) == 2:\n",
        "    if axes[0] == axes[1]:\n",
        "      out = math_ops.reduce_sum(math_ops.multiply(x, y), axes[0])\n",
        "    else:\n",
        "      out = math_ops.reduce_sum(\n",
        "          math_ops.multiply(array_ops.transpose(x, [1, 0]), y), axes[1])\n",
        "  else:\n",
        "    adj_x = None if axes[0] == ndim(x) - 1 else True\n",
        "    adj_y = True if axes[1] == ndim(y) - 1 else None\n",
        "    out = math_ops.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n",
        "  if diff:\n",
        "    if x_ndim > y_ndim:\n",
        "      idx = x_ndim + y_ndim - 3\n",
        "    else:\n",
        "      idx = x_ndim - 1\n",
        "    out = array_ops.squeeze(out, list(range(idx, idx + diff)))\n",
        "  if ndim(out) == 1:\n",
        "    out = expand_dims(out, 1)\n",
        "  return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cd17730-22b6-4ac3-a612-31f18902fa78",
        "_uuid": "61c38c7ee701bb3ee2190263cf907fcdbe40dca2",
        "id": "fvniQOFMqsmH"
      },
      "source": [
        "# Build the Model\n",
        "Here we use the layers to build up the model. The model is a bit different from a standard $X\\rightarrow y$  model, it is $(X,y)\\rightarrow (y,X)$ meaning it attempts to predict the class from the image, and then at the same time, using the same capsule reconstruct the image from the class. The approach appears very cGAN-like where the task of reconstructing better helps the model 'understand' the image data better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "bc101123-d53c-4c2e-a187-101c434885da",
        "_uuid": "2497453eb1895f624ad84617dd98c230f5640304",
        "trusted": true,
        "id": "2uyk0ed3qsmI"
      },
      "source": [
        "def CapsNet(input_shape, n_class, routings, batch_size,\n",
        "            n_filters_c1=256, \n",
        "            dim_caps_prim=8, \n",
        "            n_channels_prim=32, \n",
        "            dim_caps_sec=16):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :param batch_size: size of batch\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=n_filters_c1, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=dim_caps_prim, n_channels=n_channels_prim, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=dim_caps_sec, routings=routings, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "    print\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    # decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model(inputs=[x, y], outputs=[out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(inputs=x, outputs=[out_caps, decoder(masked)])\n",
        "    # train_model = models.Model(inputs=x, outputs=[out_caps, decoder(masked_by_y)])\n",
        "    # eval_model = models.Model(inputs=x, outputs=[out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    noise = layers.Input(shape=(n_class, 16))\n",
        "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    return train_model, eval_model, manipulate_model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "c6d84e5a-c33c-40c8-89c3-aba3454f7025",
        "_uuid": "9f27c6b0623ebffb6c8a24579f9dd4e321d6b1c2",
        "trusted": true,
        "id": "jkCdJpcTqsmL"
      },
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    # return tf.reduce_mean(tf.square(y_pred))\n",
        "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qe3dcQdaqsmR"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wP5i8pbdzWg"
      },
      "source": [
        "#### Define a Multi-Output Transformer\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq2brcsO6ogW"
      },
      "source": [
        "from typing import List\r\n",
        "\r\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
        "from sklearn.preprocessing import LabelEncoder, FunctionTransformer, OneHotEncoder\r\n",
        "\r\n",
        "\r\n",
        "class MultiOutputTransformer(BaseEstimator, TransformerMixin):\r\n",
        "\r\n",
        "    def fit(self, y):\r\n",
        "        # y_bin, y_cat = y[:, 0], y[:, 1]\r\n",
        "        y_caps, y_recons = y[:,:10],y[:,10:]\r\n",
        "        # Create internal encoders to ensure labels are 0, 1, 2...\r\n",
        "        # self.caps_encoder_ = OneHotEncoder()\r\n",
        "        # self.recons_encoder_ = FunctionTransformer(func=lambda t: t)\r\n",
        "        # # Fit them to the input data\r\n",
        "        # self.caps_encoder_.fit(y_caps)\r\n",
        "        # self.recons_encoder_.fit(y_recons)\r\n",
        "        # Save the number of classes\r\n",
        "        self.n_classes_ = [\r\n",
        "            y_caps.shape[0],\r\n",
        "            y_recons.shape[1],\r\n",
        "        ]\r\n",
        "        # Save number of expected outputs in the Keras model\r\n",
        "        # SciKeras will automatically use this to do error-checking\r\n",
        "        self.n_outputs_expected_ = 2\r\n",
        "        return self\r\n",
        "\r\n",
        "    def transform(self, y: np.ndarray) -> List[np.ndarray]:\r\n",
        "        y_caps, y_recons = y[:,:10],y[:,10:]\r\n",
        "        # Apply transformers to input array\r\n",
        "        # y_caps = self.caps_encoder_.transform(y_caps)\r\n",
        "        # y_recons = self.recons_encoder_.transform(y_recons)\r\n",
        "        # Split the data into a list\r\n",
        "        return [y_caps, y_recons]\r\n",
        "\r\n",
        "    def inverse_transform(self, y: List[np.ndarray], return_proba: bool = False) -> np.ndarray:\r\n",
        "        y_pred_proba = y  # rename for clarity, what Keras gives us are probs\r\n",
        "        if return_proba:\r\n",
        "            return np.column_stack(y_pred_proba, axis=1)\r\n",
        "        # Get class predictions from probabilities\r\n",
        "        y_pred_caps = to_categorical(np.argmax(y_pred_proba[0], axis=1), num_classes=y_pred_proba[0].shape[1])\r\n",
        "        y_pred_recons = y_pred_proba[1]\r\n",
        "        # y_pred_cat = np.argmax(y_pred_proba[1], axis=1)\r\n",
        "        # Pass back through LabelEncoder\r\n",
        "        # y_pred_caps = self.caps_encoder_.inverse_transform(y_pred_caps)\r\n",
        "        # y_pred_recons = self.recons_encoder_.inverse_transform(y_pred_recons)\r\n",
        "        return np.column_stack([y_pred_caps, y_pred_recons])\r\n",
        "    \r\n",
        "    def get_metadata(self):\r\n",
        "        return {\r\n",
        "            \"n_classes_\": self.n_classes_,\r\n",
        "            \"n_outputs_expected_\": self.n_outputs_expected_,\r\n",
        "        }"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI7yphi9gWfG"
      },
      "source": [
        "#### Compile a MIMOEstimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWGpoWlOp4Gm"
      },
      "source": [
        "def input_reshaper(X):\r\n",
        "    return [X[:,:-10].reshape(X.shape[0],28,28,1), X[:,-10:]]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBDDzQnj0Nz8"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.metrics import accuracy_score, make_scorer\r\n",
        "\r\n",
        "# Sample Scorer if you want to define your own scorer via Grid-Search CV\r\n",
        "def capsnet_scorer(estimator, X, y):\r\n",
        "  y_pred = estimator.predict(X)\r\n",
        "  y_pred_caps, y_pred_recons = y_pred[:,:10],y_pred[:,10:]\r\n",
        "  y_caps, y_recons = y[:,:10],y[:,10:]\r\n",
        "\r\n",
        "  return accuracy_score(y_caps, y_pred_caps)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_-LFxRr7p1_"
      },
      "source": [
        "class MIMOEstimator(BaseWrapper):\r\n",
        "\r\n",
        "  @property\r\n",
        "  def feature_encoder(self):\r\n",
        "      return FunctionTransformer(\r\n",
        "          func=input_reshaper,\r\n",
        "      )\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def scorer(X, #should be y_true according to documentation but present API has this definition\r\n",
        "             y, #should be y_pred according to documentation but present API has this definition\r\n",
        "             **kwargs) -> float:\r\n",
        "    y_pred_caps, y_pred_recons = y[:,:10],y[:,10:]\r\n",
        "    y_caps, y_recons = X[:,:10],X[:,10:]\r\n",
        "\r\n",
        "    return accuracy_score(y_caps, y_pred_caps)\r\n",
        "  \r\n",
        "  @property\r\n",
        "  def target_encoder(self):\r\n",
        "      return MultiOutputTransformer()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2hbEjxadhpq"
      },
      "source": [
        "# Load MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O3zhuO8-qsmj"
      },
      "source": [
        "def load_mnist():\n",
        "    # the data, shuffled and split between train and test sets\n",
        "    from tensorflow.keras.datasets import mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7iHLb4lfk4d"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CceMoO1sdl5y"
      },
      "source": [
        "#### Set Arguments/Parameters for the CV run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wtWrDxrhqsmn"
      },
      "source": [
        "class arguments():\n",
        "    def __init__(self, epochs = 50, batch_size=100, lr=0.001, lr_decay=0.9, lam_recon=0.392, r=3, \n",
        "                 shift_fraction=0.1, debug=True, save_dir=\"/content/gdrive/My Drive/EEG MLSP/Emotion Classification/outputprocesseddata\", t=False, digit=5, weights=None):\n",
        "        self.epochs=epochs\n",
        "        self.batch_size=batch_size\n",
        "        self.lr = lr\n",
        "        self.lr_decay = lr_decay\n",
        "        self.lam_recon = lam_recon\n",
        "        self.routings = r\n",
        "        self.shift_fraction = shift_fraction\n",
        "        self.debug = debug\n",
        "        self.save_dir = save_dir\n",
        "        self.testing = t\n",
        "        self.digit = digit\n",
        "        self.weights = weights\n",
        "\n",
        "args = arguments()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PTQX_Lbc7bK"
      },
      "source": [
        "### Training and Teting Single Run\r\n",
        "We are using Grid Search CV. So, we wont be using this training/testing in this iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g8R53-QCqsmY"
      },
      "source": [
        "def train(model,  # type: models.Model\n",
        "          data, args):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
        "                                           save_best_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    \"\"\"\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
        "    model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "              steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
        "              epochs=args.epochs,\n",
        "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
        "                                callbacks=[log, checkpoint, lr_decay])\n",
        "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
        "\n",
        "    model.save_weights(args.save_dir + '/trained_model.h5')\n",
        "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
        "\n",
        "    \n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f2nNvSqhqsmb"
      },
      "source": [
        "def test(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
        "\n",
        "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "    print('-' * 30 + 'End: test' + '-' * 30)\n",
        "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "    plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cZAn5mPNqsmd"
      },
      "source": [
        "def manipulate_latent(model, data, args):\n",
        "    print('-' * 30 + 'Begin: manipulate' + '-' * 30)\n",
        "    x_test, y_test = data\n",
        "    index = np.argmax(y_test, 1) == args.digit\n",
        "    number = np.random.randint(low=0, high=sum(index) - 1)\n",
        "    x, y = x_test[index][number], y_test[index][number]\n",
        "    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
        "    noise = np.zeros([1, 10, 16])\n",
        "    x_recons = []\n",
        "    for dim in range(16):\n",
        "        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "            tmp = np.copy(noise)\n",
        "            tmp[:, :, dim] = r\n",
        "            x_recon = model.predict([x, y, tmp])\n",
        "            x_recons.append(x_recon)\n",
        "\n",
        "    x_recons = np.concatenate(x_recons)\n",
        "\n",
        "    img = combine_images(x_recons, height=16)\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n",
        "    print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n",
        "    print('-' * 30 + 'End: manipulate' + '-' * 30)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "169b7f78-12c7-4fed-886e-60024fe59339",
        "_uuid": "02b7db879a533e7bfb3116522bebf3867b23498c",
        "trusted": true,
        "id": "2buKnV8eqsmg"
      },
      "source": [
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(np.sqrt(num))\n",
        "    height = int(np.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "def test(model, data):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict([x_test, y_test], batch_size=100)\n",
        "    print('-'*50)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    from PIL import Image\n",
        "\n",
        "    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(\"real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to ./real_and_recon.png')\n",
        "    print('-'*50)\n",
        "    plt.imshow(plt.imread(\"real_and_recon.png\", ))\n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdPEgZcufzgT"
      },
      "source": [
        "### Cross-Validated Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVVRZnALeeUr"
      },
      "source": [
        "#### Model Getter\r\n",
        "Called from MIMOEstimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDYXWlqg05rh"
      },
      "source": [
        "def get_model(input_shape,\r\n",
        "              n_class,\r\n",
        "              routings,\r\n",
        "              n_filters_c1,\r\n",
        "              batch_size=args.batch_size,\r\n",
        "              model_type='train'):\r\n",
        "  \r\n",
        "  model, eval_model, manipulate_model = CapsNet(input_shape=input_shape,\r\n",
        "                                              n_class=n_class,\r\n",
        "                                              routings=routings,\r\n",
        "                                              n_filters_c1 = n_filters_c1,\r\n",
        "                                              batch_size=batch_size)\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  # Plot model graph\r\n",
        "  model_plotter(model, show_shapes=True, show_layer_names=True, to_file='model.png')\r\n",
        "  from IPython.display import Image as ipy_img\r\n",
        "  ipy_img(retina=True, filename='model.png')\r\n",
        "  \r\n",
        "  if model_type == 'train':\r\n",
        "    # compile the model\r\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\r\n",
        "                  loss=[margin_loss, 'mse'],\r\n",
        "                  loss_weights=[1., args.lam_recon],\r\n",
        "                  metrics={'capsnet': 'accuracy'})\r\n",
        "    return model\r\n",
        "  elif model_type == 'test':\r\n",
        "    return eval_model\r\n",
        "  elif model_type == 'manipulate':\r\n",
        "    return manipulate_model\r\n",
        "  else:\r\n",
        "    print ('Enter a Valid Model Type')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2e2eKp3exfS"
      },
      "source": [
        "#### Change data into scikit format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL-9IfMQHp9g"
      },
      "source": [
        "def get_sciki_xy(X,y):\r\n",
        "  X_sciki = np.column_stack([X.reshape((y.shape[0], np.prod(X.shape[1:]))), y])\r\n",
        "  y_sciki = np.column_stack([y,X.reshape((y.shape[0], np.prod(X.shape[1:])))])\r\n",
        "\r\n",
        "  return X_sciki,y_sciki"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ8t2-Sae5gL"
      },
      "source": [
        "#### Define the function to setup cross validation and make a run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB50PYzI39wF"
      },
      "source": [
        "def get_cross_val():\r\n",
        "  (x_train_, y_train_), (x_test_, y_test_) = load_mnist()\r\n",
        "\r\n",
        "  x_train, y_train = get_sciki_xy(x_train_[:1000], y_train_[:1000])\r\n",
        "\r\n",
        "  x_test, y_test = get_sciki_xy(x_test_[:100],y_test_[:100])\r\n",
        "\r\n",
        "  # callbacks\r\n",
        "  log = callbacks.CSVLogger(args.save_dir + '/log.csv')\r\n",
        "  checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\r\n",
        "                                          save_best_only=True, verbose=1)\r\n",
        "  lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\r\n",
        "\r\n",
        "  clf = MIMOEstimator(model = get_model,\r\n",
        "                        model__input_shape=x_train_.shape[1:],\r\n",
        "                        model__n_class=len(np.unique(np.argmax(y_train_, 1))),\r\n",
        "                        model__routings=args.routings,\r\n",
        "                        model__batch_size = args.batch_size,\r\n",
        "                        model__n_filters_c1=256, \r\n",
        "                        # epochs=args.epochs, \r\n",
        "                        # callbacks=[log, checkpoint, lr_decay],\r\n",
        "                        model__model_type = 'train')\r\n",
        "  print(\"X input shape = \", x_train.shape)\r\n",
        "  print(\"Y input shape = \", y_train.shape)\r\n",
        "  # clf.fit(X=x_train, \r\n",
        "  #         y=y_train,\r\n",
        "  #         )\r\n",
        "  # print('Score = ', clf.score(x_test, y_test))\r\n",
        "\r\n",
        "  params = {'model__n_filters_c1': [128,256],\r\n",
        "            'model__routings': [4,5]}\r\n",
        "  \r\n",
        "  # no. of examples/cv should be completely divisible by batch_size\r\n",
        "  gs = GridSearchCV(estimator=clf, param_grid=params, cv=5, scoring=capsnet_scorer, verbose=True)\r\n",
        "  gs_res = gs.fit(X=x_train, \r\n",
        "                  y=y_train)\r\n",
        "  print(\"Grid Search Results: \")\r\n",
        "  print(gs_res)\r\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91N5nek5P2_r",
        "outputId": "a8e5fb2d-5148-4fad-ef36-633a04ed792f"
      },
      "source": [
        "get_cross_val()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X input shape =  (1000, 794)\n",
            "Y input shape =  (1000, 794)\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_9 (Mask)                   (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_9[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 23s 29ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.0825\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_12 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_12[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 23s 29ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1100\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_15 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_15[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 23s 29ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1138\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_18 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_18[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 23s 29ms/sample - loss: 0.8997 - capsnet_loss: 0.8094 - decoder_loss: 0.2302 - capsnet_accuracy: 0.1363\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_21 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_21[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 24s 29ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.0787\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_24\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_24 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_24[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 24s 30ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2300 - capsnet_accuracy: 0.1000\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_27\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_28 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_27 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_27[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 24s 31ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2300 - capsnet_accuracy: 0.1300\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_30\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_30 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_30[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 24s 30ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.0950\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_34 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_33 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_33[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 24s 30ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1412\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_37 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_38 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_36 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_36[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 24s 31ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1513\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_40 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_41 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_39 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_39[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 40s 50ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2300 - capsnet_accuracy: 0.1312\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_43 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_44 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_42 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_42[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 36s 45ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2300 - capsnet_accuracy: 0.0587\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_46 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_47 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_45 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_45[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 36s 45ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1525\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_48\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_49 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_50 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_48 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_48[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 36s 45ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.0737\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_51\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_52 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_53 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_51 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_51[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 36s 45ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.0662\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_54\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_55 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_56 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_54 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_54[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 37s 46ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2300 - capsnet_accuracy: 0.0838\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_57\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_58 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_59 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_57 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_57[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 37s 46ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.0650\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_60\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_61 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_62 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_60 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_60[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 38s 47ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1175\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_63\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_64 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_65 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_63 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_63[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 37s 46ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2301 - capsnet_accuracy: 0.1100\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (800, 10)\n",
            "Recons Y shape:  (800, 784)\n",
            "Model: \"model_66\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_67 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 256)   20992       input_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     5308672     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_68 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_66 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_66[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,215,568\n",
            "Trainable params: 8,215,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 800 samples\n",
            "800/800 [==============================] - 37s 47ms/sample - loss: 0.8996 - capsnet_loss: 0.8094 - decoder_loss: 0.2300 - capsnet_accuracy: 0.0637\n",
            "Input Reshaped\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of y-pred:  (200, 10) (200, 784)\n",
            "Caps Prediction Shape:  (200, 10)\n",
            "Recons Prediction Shape:  (200, 784)\n",
            "Capsule Y shape:  (1000, 10)\n",
            "Recons Y shape:  (1000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 12.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_69\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_70 (InputLayer)           [(100, 28, 28, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (100, 20, 20, 128)   10496       input_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (100, 6, 6, 256)     2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (100, 1152, 8)       0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (100, 1152, 8)       0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (100, 10, 16)        1474560     primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_71 (InputLayer)           [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_69 (Mask)                  (100, 160)           0           digitcaps[0][0]                  \n",
            "                                                                 input_71[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (100, 10)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 784)          1411344     mask_69[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,550,864\n",
            "Trainable params: 5,550,864\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Input Reshaped\n",
            "Train on 1000 samples\n",
            "1000/1000 [==============================] - 30s 30ms/sample - loss: 0.8994 - capsnet_loss: 0.8094 - decoder_loss: 0.2295 - capsnet_accuracy: 0.0870\n",
            "Grid Search Results: \n",
            "GridSearchCV(cv=5, error_score=nan,\n",
            "             estimator=MIMOEstimator(batch_size=None, build_fn=None, callbacks=None, epochs=1, loss=None, metrics=None, model=<function get_model at 0x7fa0a93e8048>, model__input_shape=(28, 28, 1), model__model_type='train', model__n_class=10, model__n_filters_c1=256, model__routings=3, optimizer='rmsprop', random_state=None, run_eagerly=False, shuffle=True, validation_split=0.0, verbose=1, warm_start=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'model__n_filters_c1': [128, 256],\n",
            "                         'model__routings': [4, 5]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=<function capsnet_scorer at 0x7fa0a93e88c8>, verbose=True)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}